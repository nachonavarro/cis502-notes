%!TEX root = ../main.tex

(Some time spent on discussing the midterm). 

\section{Longest Increasing Subsequence Problem}

For this problem, the
input is a
sequence of integers.
The output for this problem is the longest increasing subsequence.

Recall that $\text{Best}(i, l) = x$ if the increasing sequence of length $l$
in the prefix of $a_1, ..., a_i$ with the smallest ending number
ends in $x$. Inductively, assume that for some $i$ we have computed
$\text{Best}(i, l)$ for all $l$. When we see $a_{i+1}$, what should we
do? Consider the sequence

$$
5, 10, 7, 3, 8, 4, 9, 6
$$

Then $\text{Best}(1, 1) = 5$, and $\text{Best}(1, l) = \infty$ for any
$l$ that is greater than 1. We also have for instance that
$\text{Best}(4, 1) = 3$, $\text{Best}(4, 2) = 7$, and $\text{Best}(4,
l) = \infty$ for any $l$ that is greater than 2. We also have
that $\text{Best}(5, 1) = 3$, $\text{Best}(5, 2) = 7$,
$\text{Best}(5, 3) = 8$.

There's an $O(n\log(n))$ algorithm relying on binary search to solve
this problem. For more info, see \href{https://en.wikipedia.org/wiki/Longest_increasing_subsequence#Efficient_algorithms}{here}.


\section{All Pairs Shortest Paths}

The input to this problem is a weighted, directed graph $G = (V, E)$.
The goal is to compute a matrix $D$ of shortest paths distances between
every pair of vertices. More formally, $D_{ij}$ denotes the shortest
path from vertex $i$ to vertex $j$.

\subsection{Adjacency Matrix Approach}

Suppose we have the adjacency matrix $A$ of $G$ where
$A[i, j] = w(i, j)$ if $(i, j) \in E$ and $\infty$ otherwise.
What does $A^2$ mean? 
In the traditional matrix multiplication sense, we would have that 
$A^2[i, j] = \sum_k A[i,k] \cdot A[k, j]$. But replace the
multiplication with addition and we will let
$A^2[i, j] = \min_k A[i,k] + A[k, j]$. Note that
$(+, \min)$ form a semiring. Notice that then
$A^2$ in the $(+, \min)$ semiring gives the length of the 
shortest path consisting of at most two hops between every pair
of vertices.

You can prove by induction that $A^n$ contains the lengths
of shortest paths consisting of at most $n$ hops between every 
pair of vertices.

First of all notice that any shortest path doesn't contain cycles, for
if it did, you could remove the cycle (all weights are non-negative),
and it will still be the shortest path (so all shortest paths
are simple). The longest simple path on $n$ vertices is
$n - 1$, and therefore $A^
{n-1}$ gives the length of the shortest
paths between every pair of vertices.

The best algorithm that computes standard matrix multiplication
runs in approximately $n^{2.3}$. For our semiring, it's still
roughly $n^3$.

What if instead of computing $A^{n-1}$ we compute $A^l$ for some
$l \geq n - 1$? Since $n - 1$ is the longest possible path, computing
$A^l$ will still equal $A^{n-1}$, so we can choose to compute any
$A^l$ for any $l \geq n - 1$. For ease of computation, choose
$A^{2^k}$ where $2^k \geq n - 1$. The computation will now be
$A \to A^2 \to A^{2^2} \to ... \to A^{2^k}$, which means
we only perform $k \approx \log(n)$ multiplications. Each one
takes $n^3$, so the algorithm runs in $O(n^3\log(n))$.


This algorithms assumes there are no negative weight cycles.
If there are negative weight cycles, and $i$ is a vertex in such a
cycle, then $A^l[i, i]$ will be negative instead of 0, so this
algorithms also gives us a way of finding negative weight cycles in a
graph.

\subsection{DP Approach: Floyd-Warshall Algorithm}

Fix a numbering of the vertices as $1, 2, ..., n$.
Let $C^k(i, j)$ be the length of the shortest path from $i$ to $j$
where every intermediate vertex is numbered less than or equal to $k$.
Note $C^n(i, j)$ is just the shortest path from $i$ to $j$ with no
constraints, and


\begin{equation*}
    C^0(i, j) =
    \begin{cases}
    0 & i = j \\
    w(i, j) & (i, j) \in E \\
    \infty & \text{otherwise}
    \end{cases}
\end{equation*}

and this is just the adjacency matrix of $G$! The approach for
the Floyd-Warshall Algorithm is to incrementally compute 
$C^k(i, j)$ until $k = n$. The key question is then: given we know
$C^k(i, j)$ for all $i, j$, how do we compute $C^{k + 1}(i, j)$?
There are two possibilities.

\begin{itemize}
    \item The path from $i$ to $j$ restricted to vertices numbered $k
    + 1$ or less does not go through vertex $k + 1$. In which case
    $C^{k + 1}(i, j) = C^k(i, j)$.
    \item The path from $i$ to $j$ restricted to vertices numbered $k
    + 1$ or less does indeed go through vertex $k + 1$. Then it only
    goes through it exactly once (otherwise we would have a cycle).
    Therefore 
    $$
    C^{k + 1}(i, j) = \minÂ \Big (C^k(i, j), \; C^k(i, k + 1) + C^k(k +
    1,
    j) \Big )
    $$
\end{itemize}












